{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dmurali/miniconda3/lib/python3.4/site-packages/pandas/core/index.py:6031: RuntimeWarning: unorderable types: str() > int(), sort order is undefined for incomparable objects\n",
      "  result = result.union(other)\n",
      "/Users/dmurali/miniconda3/lib/python3.4/site-packages/pandas/core/index.py:5999: RuntimeWarning: unorderable types: str() > int(), sort order is undefined for incomparable objects\n",
      "  union = _union_indexes(indexes)\n",
      "/Users/dmurali/miniconda3/lib/python3.4/site-packages/IPython/kernel/__main__.py:171: FutureWarning: convert_objects is deprecated.  Use the data-type specific converters pd.to_datetime, pd.to_timedelta and pd.to_numeric.\n",
      "/Users/dmurali/miniconda3/lib/python3.4/site-packages/IPython/kernel/__main__.py:180: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/dmurali/miniconda3/lib/python3.4/site-packages/IPython/kernel/__main__.py:181: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictedClass     0    1\n",
      "isSpam                   \n",
      "0               3796  169\n",
      "1                287   13\n",
      "0s: 3796, 1s: 13\n",
      "Accuracy: 0.359\n",
      "Precision: 0.026\n",
      "Output written to spamSiteFeatureImportance_rf.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dmurali/miniconda3/lib/python3.4/site-packages/pandas/core/frame.py:2650: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from MongoClient import read_mongo\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.grid_search import RandomizedSearchCV\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#set some intial vars\n",
    "algorithm = 'rf'\n",
    "\n",
    "def reportModelMetric(model, metric, trainingData, algo):\n",
    "    if metric == 'featureImportance':\n",
    "        modelMetric =  pd.DataFrame(model.feature_importances_, columns = ['ModelMetric'])\n",
    "    \n",
    "    #format the important features predicted by the model\n",
    "    features = pd.DataFrame(trainingData.columns.values, columns = ['Features'])\n",
    "    importanceByFeature = pd.concat([features, modelMetric], axis = 1)\n",
    "    importanceByFeature.sort_values(by = ['ModelMetric'], inplace = True, ascending = False)\n",
    "    #write to file\n",
    "    importanceByFeature.to_csv('../spamSiteFeatureImportance_'+algo+'.csv', index = False)\n",
    "    print('Output written to spamSiteFeatureImportance_'+algo+'.csv')\n",
    "\n",
    "def predictAndReport(algo, bestParams, train, test):\n",
    "    if algo == 'rf':\n",
    "        predictor = RandomForestClassifier(min_samples_split = 16, n_estimators = 60, \n",
    "                                           min_samples_leaf = 10)\n",
    "    elif algo == 'knn':\n",
    "        predictor = KNeighborsClassifier(n_neighbors = 1, weights = 'distance')\n",
    "    elif algo == 'logr':\n",
    "        predictor = LogisticRegression()\n",
    "    \n",
    "    predictor.fit(train, train['isSpam'])\n",
    "    if algo == 'logr':\n",
    "        coefficients = pd.DataFrame(predictor.coef_[0], columns = ['Coefficients'])\n",
    "        features = pd.DataFrame(train.columns.values, columns = ['Features'])\n",
    "        featureCoefficients = pd.concat([features, coefficients], axis = 1)\n",
    "        featureCoefficients.sort_values(by = ['Coefficients'], inplace = True, ascending = False)\n",
    "        featureCoefficients.to_csv('../spamSiteFeatureCoefficients_'+algo+'.csv', index = False)\n",
    "        print('Coefficients written to spamSiteFeatureCoefficients_'+algo+'.csv')\n",
    "    predicted = predictor.predict(test)\n",
    "    \n",
    "    dfWithClass = pd.DataFrame(predicted, columns = ['predictedClass'])\n",
    "    final = pd.concat([test, dfWithClass], axis=1)\n",
    "    #take a look at the confusion matrix\n",
    "    print(pd.crosstab(final.isSpam, final.predictedClass))\n",
    "    print(\"0s: %d, 1s: %d\" %(np.sum((final.isSpam == 0) & (final.predictedClass == 0)), np.sum((final.isSpam == 1) & (final.predictedClass == 1))))\n",
    "    print(\"Accuracy: %.3f\" %float(np.sum(final.isSpam == final.predictedClass) / float(len(test))))\n",
    "    print(\"Precision: %.3f\" %float(np.sum((final.isSpam == 1) & (final.predictedClass == 1)) / np.sum(final.isSpam == 1)))\n",
    "    if algo == 'rf':\n",
    "        reportModelMetric(predictor, 'featureImportance', train, algo)\n",
    "\n",
    "def searchBestModelParameters(algorithm, trainingData):\n",
    "    #using randomforest\n",
    "    if algorithm == 'rf':\n",
    "        numTrees = range(10, 100, 10)\n",
    "        numMinLeafSamples = range(2, 20, 2)\n",
    "        numMinSamplesSplit = range(1, 20, 3)\n",
    "        paramDistribution = dict(n_estimators = numTrees, min_samples_leaf = numMinLeafSamples, min_samples_split = numMinSamplesSplit)\n",
    "        model = RandomForestClassifier()\n",
    "    elif algorithm == 'knn':\n",
    "        # model the data using knn\n",
    "        # define the parameter values that should be searched\n",
    "        k_range = range(1, 50)\n",
    "        weight_options = ['uniform', 'distance']\n",
    "        # specify \"parameter distributions\" rather than a \"parameter grid\"\n",
    "        paramDistribution = dict(n_neighbors = k_range, weights = weight_options)\n",
    "        model = KNeighborsClassifier()\n",
    "    elif algorithm == 'logr':\n",
    "        #model data using logistic regression\n",
    "        model = LogisticRegression()\n",
    "        %time print(np.sqrt(-cross_val_score(model, trainingData, trainingData['isSpam'], cv=10, scoring='mean_squared_error')).mean())\n",
    "        return\n",
    "            \n",
    "    bestRun = []\n",
    "    for _ in range(20):\n",
    "        rand = RandomizedSearchCV(model, paramDistribution, cv=10, scoring = 'accuracy', n_iter = 10)\n",
    "        rand.fit(trainingData, trainingData['isSpam'])\n",
    "        # examine the best model\n",
    "        bestRun.append({'score' : round(rand.best_score_,3), 'params' : rand.best_params_})\n",
    "    print(max(bestRun, key=lambda x:x['score']))\n",
    "    return max(bestRun, key=lambda x:x['score'])\n",
    "    \n",
    "\n",
    "\n",
    "#read site\n",
    "rawSite = read_mongo(db = 'CB', collection = 'site', host = 'localhost', no_id = False)\n",
    "siteModified = rawSite.drop(['dismissedOnboarding', 'feedCounter', 'feedToken',\n",
    "              'modules', 'password', 'theme', 'photoId', 'requestAccess',\n",
    "              'requestPassword', 'bi', 'photo', 'goFundMe', 'lastName',\n",
    "              'numAmps', 'partner', 'size', 'theme', 'createFormSessionId', 'allowList',\n",
    "              'blockList', 'displayEmail', 'isPhotoOrderingFixed', 'healthCondition',\n",
    "              'spam', 'status', 'firstName', 'lastInvite', 'isDeleted',\n",
    "              'hasCommentFix','age'], axis = 1)\n",
    "viewPort = siteModified.cm.apply(pd.Series).fillna(-1)\n",
    "siteModified['hasJavaScriptOn'] = [0 if vp == -1 else 1 for vp in viewPort.vpw]\n",
    "siteModified.drop(['cm'], axis = 1, inplace = True)\n",
    "siteModified['descriptionLen'] = rawSite.description.str.len()\n",
    "siteModified.drop(['description'], axis = 1, inplace = True)\n",
    "siteModified['nameLen'] = rawSite.name.str.len()\n",
    "siteModified.drop(['name'], axis = 1, inplace = True)\n",
    "siteModified['titleLen'] = rawSite.title.str.len()\n",
    "siteModified.drop(['title'], axis = 1, inplace = True)\n",
    "\n",
    "siteCreatedDayOrNight = ['Night' if(hr >= 22 or hr <= 6) else 'Day' for hr in pd.DatetimeIndex(siteModified['createdAt']).hour]\n",
    "siteModified['siteCreatedDayOrNight'] = siteCreatedDayOrNight\n",
    "siteModified.drop(['createdAt'], axis = 1, inplace = True)\n",
    "siteUpdatedDayOrNight = ['Night' if(hr >= 22 or hr <= 6) else 'Day' for hr in pd.DatetimeIndex(siteModified['updatedAt']).hour]\n",
    "siteModified['siteUpdatedDayOrNight'] = siteUpdatedDayOrNight\n",
    "siteModified.drop(['updatedAt'], axis = 1, inplace = True)\n",
    "\n",
    "siteModified.descriptionLen.replace(np.nan, -1, inplace = True)\n",
    "siteModified.hasVisitorInvite.replace(np.nan, 0, inplace = True)\n",
    "siteModified.isForSelf.replace(np.nan, 0, inplace = True)\n",
    "siteModified.isSearchable.replace(np.nan, 0, inplace = True)\n",
    "siteModified.isSpam.replace(np.nan, 0, inplace = True)\n",
    "siteModified.sawReCaptcha.replace(np.nan, 0, inplace = True)\n",
    "\n",
    "siteModified.rename(columns={'_id': 'siteId', 'sawReCaptcha' : 'sawReCaptchaSite', 'isSpam' : 'isSiteSpam'}, inplace=True)\n",
    "\n",
    "binarizedSites = pd.get_dummies(siteModified, columns = ['platform', 'privacy', 'siteCreatedDayOrNight', 'siteUpdatedDayOrNight'])\n",
    "\n",
    "#print(siteModified.groupby(['siteUpdatedDayOrNight']).size())\n",
    "#read profile\n",
    "rawProfile = read_mongo(db = 'CB', collection = 'profile', host = 'localhost', no_id = False)\n",
    "profileModified = rawProfile.drop(['ampProfile', 'bio', 'cm', 'country', 'createFormSessionId', 'employer',\n",
    "                'feedCounter', 'guid', 'howFoundOther', 'language', 'lastDrawingTool',\n",
    "                'lastLastLogin', 'lastLogin', 'lastModifier', 'lastName', 'firstName',\n",
    "                'lastVideoUpload', 'location', 'mailingAddress', 'mobile', 'my', 'n',\n",
    "                'notes', 'password', 'phone', 'photo', 'platform', 'sms', 'social',\n",
    "                'tz', 'whitelistedByCustomerCare', 'handle', 'createdAt', 'updatedAt',\n",
    "                'lastActivity', 'lastJournalReply', 'ip', 'howFound', 'isStub', 'failedLoginAttempts',\n",
    "                'isMailSubscriber', 'spam', 'email', 'isSecure', 'isPrivate', 'isPublic',\n",
    "                'gender', 'isDeleted'], axis = 1)\n",
    "#emails = profileModified.email.apply(pd.Series)\n",
    "#emailDomains = pd.DataFrame(emails.domain.values, columns = ['emailDomain'])\n",
    "#withoutEmail = profileModified.drop(['email'], axis = 1)\n",
    "#withDomains = pd.concat([withoutEmail, emailDomains], axis = 1).fillna('blank')\n",
    "profileModified.sawReCaptcha.replace(np.nan, 0, inplace = True)\n",
    "profileModified.numNotifications.replace(np.nan, -1, inplace = True)\n",
    "\n",
    "profileModified.rename(columns={'_id': 'profileId', 'sawReCaptcha' : 'sawReCaptchaProfile'}, inplace=True)\n",
    "\n",
    "#read site_profile\n",
    "rawSiteProfile = read_mongo(db = 'CB', collection = 'site_profile', host = 'localhost')\n",
    "siteProfile = pd.DataFrame(rawSiteProfile['siteId'], columns = ['siteId'])\n",
    "siteProfile['profileId'] = rawSiteProfile.userId\n",
    "\n",
    "#read site_profile with spam\n",
    "octSiteProfileSpam = pd.read_csv(\"/Users/dmurali/Documents/spamlist_round25_from_20150809_to_20151015.csv\",\n",
    "                    usecols = ['siteId','isSpam'])\n",
    "octSiteProfileSpam.rename(columns = {'isSpam':'isOctSpam'}, inplace = True)\n",
    "\n",
    "\n",
    "mergedSiteProfile = binarizedSites.merge(siteProfile, how='left', on = ['siteId'], sort = False).merge(profileModified, how='left', on = ['profileId'], sort = False).merge(octSiteProfileSpam, how='left', on = ['siteId'], sort = False)\n",
    "mergedSiteProfile['isSpam'] = np.where(mergedSiteProfile['isOctSpam'].isin(mergedSiteProfile['isSiteSpam']), 1, mergedSiteProfile['isSiteSpam'])\n",
    "\n",
    "mergedSiteProfile = mergedSiteProfile.convert_objects(convert_numeric=True)\n",
    "mergedSiteProfile.drop(['isSiteSpam', 'isOctSpam'], axis = 1, inplace = True)\n",
    "\n",
    "train, test, spamLabelTrain, spamLabelTest = train_test_split(mergedSiteProfile, mergedSiteProfile['isSpam'], test_size = 0.4)       \n",
    "#isSpamTest = mergedSiteProfile.loc[mergedSiteProfile['isSpam'] == 1][:350]\n",
    "#isNotSpamTest = mergedSiteProfile.loc[mergedSiteProfile['isSpam'] == 0][:6300]\n",
    "#test = pd.concat([isSpamTest, isNotSpamTest])\n",
    "#train = mergedSiteProfile[~mergedSiteProfile.siteId.isin(test.siteId)]\n",
    "\n",
    "train.drop(['siteId', 'profileId'], axis = 1, inplace = True)\n",
    "test.drop(['siteId', 'profileId'], axis = 1, inplace = True)\n",
    "train.fillna(-1, inplace = True)\n",
    "test.fillna(-1, inplace = True)\n",
    "#train['visits'].hist(by = train['isSpam'])\n",
    "\n",
    "#plt.hist(train['visits'].values)\n",
    "#plt.title(\"Distribution\")\n",
    "#plt.xlabel(\"Value\")\n",
    "#plt.ylabel(\"Frequency\")\n",
    "#plt.show()\n",
    "\n",
    "bestParams = []\n",
    "\n",
    "#bestParams = searchBestModelParameters(algorithm, train)\n",
    "\n",
    "predictAndReport(algorithm, bestParams, train, test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
